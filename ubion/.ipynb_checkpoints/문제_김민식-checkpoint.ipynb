{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파킨슨병 데이터\n",
    "- 환자들의 뇌를 촬영한 사진의 상태를 기록한 자료에 각 환자의 상태 status(1: 파킨슨병 진단, 0: 파킨슨병 아님)로 추가한 테이블\n",
    "- (data/parkinsons.csv)\n",
    "1. 파킨슨 병을 예측하는 모델로 로지스틱 회귀모형을 적용하여 생성\n",
    "2. 파킨슨병을 예측하는데 영향을 미치는 변수를 중요한 순서대로 3개 선정\n",
    "3. 파킨슨 병을 진단하는 기준를 함수로 생성하여(매개변수명 = threshold, 함수명 = cutoff)을 0.5로 했을 때와 0.8로 했을 때 F1-스코어를 비교\n",
    "    - 분석 조건\n",
    "        - 필요 없는 컬럼 name을 삭제\n",
    "        - 데이터의 정규화는 min-max 스케일러 사용\n",
    "        - 로지스틱 회귀를 위한 상수항 추가\n",
    "        - status는 카테고리 타입으로 변환\n",
    "        - 트레이닝셋과 테스트셋 비율은 9:1\n",
    "        - 모델은 로지스틱 회귀분석 사용\n",
    "        - 모델의 최적화 방법론은 \"bfgs\" 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df= pd.read_csv('../ubion/data/Parkinsson disease.csv')\n",
    "df.head(1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'spread1',\n",
       "       'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "scale = MinMaxScaler()\n",
    "lg = LogisticRegression(solver='lbfgs')\n",
    "# 'bfgs'\n",
    "# 기울기 추정을 위해 이전 기울기 정보를 사용하며, 경사하강법을 쓰고, hessian 행렬 업데이트 방법을 사용\n",
    "# hessian 행렬 방식은 피쳐가 많은 비선형 문제에서 효과적임. \n",
    "# 근데 로지스틱엔 bfgs없으므로 lbfgs사용 \n",
    "# 두 방법의 차이는 메모리 사용방식의 차이이며, lbfgs가 훨씬 더 메모리 효율적\n",
    "\n",
    "x=df.drop(['status','name'], axis=1)\n",
    "\n",
    "x=scale.fit_transform(x)\n",
    "y=df['status'].astype('category')\n",
    "\n",
    "x_tr,x_test,y_tr,y_test = train_test_split(x,y, test_size=0.1, stratify=y, random_state=12)\n",
    "\n",
    "lg1=lg.fit(x_tr,y_tr.ravel())\n",
    "coef=pd.DataFrame(data=lg1.coef_,columns=df.drop(['status','name'],axis=1).columns)\n",
    "\n",
    "coef.iloc[0].nlargest(3) #spread1, spread2, PPE 가 핵심 3개\n",
    "pred=lg.predict_proba(x_test)[:,1] # 1일확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score=f1_score\n",
    "def cutoff(threshold):\n",
    "    result=[]\n",
    "    for i in range (0,len(pred),1):\n",
    "        if pred[i]>threshold:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    f1_threshold=score(result,y_test)\n",
    "    \n",
    "    result2=[]\n",
    "    for i in range (0,len(pred),1):\n",
    "        if pred[i]>0.5:\n",
    "            result2.append(1)\n",
    "        else:\n",
    "            result2.append(0)\n",
    "    f1_half=score(result2,y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return print(f'설정된 임계점의 f1값:{f1_threshold}\\n 임계점0.5일때 f1값:{f1_half}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 임계점의 f1값:0.6666666666666667\n",
      " 임계점0.5일때 f1값:0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "cutoff(0.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "eccee16ee1f2ca6b29c61e3c4642a90ff58e47b250cd293abf19e9e3b8422bd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
